{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Omqem74XY19j"
   },
   "source": [
    "# Neural Network - How to train a neural network on tabular data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8dT4j0GY8aW"
   },
   "source": [
    "## 1 - Create the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_0ph4ja_ZFma"
   },
   "source": [
    "Let us consider the toy dataset below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_MFYuVldYpJ5",
    "outputId": "2b4ba263-3e0c-4e78-eacd-4dae35ccba64"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Generate a classification dataset composed of two circles\n",
    "X_train, y_train = make_circles(n_samples=10000, noise=0.17)\n",
    "X_test, y_test = make_circles(n_samples=10000, noise=0.17)\n",
    "\n",
    "# Plot the generated dataset\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='bwr')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Generated Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YTWzGM9PZD1Y",
    "outputId": "84df5970-0540-4fff-af09-493c183334c0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_test = pd.DataFrame(X_test)\n",
    "\n",
    "#Create training data\n",
    "x_data = torch.tensor(df_train.values, dtype=torch.float32)\n",
    "y_data = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "#Create test data\n",
    "x_data_test = torch.tensor(df_test.values, dtype=torch.float32)\n",
    "y_data_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "type(x_data), type(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owpfTNFQbKro"
   },
   "source": [
    "**1) Split the training set into a new training set and a validation set (80%/20%). The validation set will be used to train the network, whereas the test set will only be used in the end to evaluate the performance of our network.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFMbQAwIZwHg"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVuz3ZudbpKK"
   },
   "source": [
    "**2) What is the size of all the objects you have created at the previous question?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "okiAZnGIZwFB",
    "outputId": "5873ae46-32c6-4854-9545-ff96ca19cd5d"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBR7iX0fczIL"
   },
   "source": [
    "**3) By looking at the documentation below, define a 'NeuralNetwork' class for a network architecture composed of two hidden layers (64 neurons per layer, sigmoid activation function) and an output layer.**\n",
    "\n",
    " https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pTyzR91OZ_vv"
   },
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "hidden_dim = 64\n",
    "output_dim = 1\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TO DO \n",
    "\n",
    "        # END TO DO \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TO DO \n",
    "\n",
    "        # END TO DO \n",
    "        return out\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Fup1X7TeciH"
   },
   "source": [
    "**4) You have just created the class but no networks have been created. Instantiate the class by creating one network that belongs to it.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFQwP5yyeb74",
    "outputId": "4604a97a-e019-48ea-9a66-1f614fc44590"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "88s5bNTSfSz6"
   },
   "source": [
    "**5) Compute the prediction of the network for the first ten observations in the test set. Beware, since you manipulate tensors, operations (even the most elementary ones) must be done through 'torch' environment and not 'numpy' environment.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKyF1MeIe-_H",
    "outputId": "dc581770-b30c-4c02-e6a2-ff0e74a236b1"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sstoyXd-ivgg"
   },
   "source": [
    "**6) Discuss the error of the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7_MS3e-wi4aP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgFp_2IUjRQQ"
   },
   "source": [
    "## 2 - Train the network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LymbPjyVkHd-"
   },
   "source": [
    "In order to train the network, we need to define a loss and an optimizer. This is done in the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQix-I9XkUR7"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRNLBFfVk2aE"
   },
   "source": [
    "**7) Why do we use the cross-entropy loss? Why do we need to specify model.parameters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1A7NAfYpk8dl"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUEAwqZKi2AB"
   },
   "source": [
    "**8) Use the following code to train the network. Make sure to understand each line.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3x4uoR2Vl3GF",
    "outputId": "d0611889-5a15-4e88-ce07-d1fa4419d225"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item()\n",
    "    acc = correct / len(y_pred) * 100\n",
    "    return acc\n",
    "\n",
    "#Initialize the model \n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Create TensorDataset and DataLoader for training data\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "#Store the values at each epoch in the following objects\n",
    "epoch_count, train_loss_values, valid_loss_values, train_acc_values, valid_acc_values = [], [], [], [], []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss_values_temp = []\n",
    "    train_acc_values_temp = []\n",
    "\n",
    "    for inputs, targets in train_dataloader:\n",
    "        # Forward pass - compute the predictions\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        \n",
    "        #Compute the loss used for the optimization\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        #Compute the accuracy, used for monitoring the model through epochs.\n",
    "        acc = accuracy_fn(targets>1/2, outputs>1/2)\n",
    "        \n",
    "        train_loss_values_temp.append(loss.detach().numpy()/len(targets))\n",
    "        train_acc_values_temp.append(acc)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss after every epoch\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval() \n",
    "\n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        #Compute the predictions on the validation set\n",
    "        output_valid = model(x_valid)   \n",
    "        output_valid = output_valid.squeeze()\n",
    "        \n",
    "        # Compute the loss and the accuracy on the validation set\n",
    "        valid_loss = criterion(output_valid, y_valid)\n",
    "        valid_acc = accuracy_fn(y_valid>1/2, output_valid>1/2)    \n",
    "\n",
    "    # Print the loss and the accuracy on the training set and validation set for each epoch\n",
    "    \n",
    "    print(f'Epoch: {epoch:4.0f} | Train Loss: {np.mean(train_loss_values_temp):.5f}, Accuracy: {np.mean(train_acc_values_temp):.2f}% | Validation Loss: {valid_loss/len(y_valid):.5f}, Accuracy: {valid_acc:.2f}%')\n",
    "    valid_acc_values.append(valid_acc)\n",
    "    valid_loss_values.append(valid_loss.detach().numpy()/ len(y_valid))\n",
    "    train_acc_values.append(np.mean(train_acc_values_temp))\n",
    "    train_loss_values.append(np.mean(train_loss_values_temp))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaE0jM0lmgDG"
   },
   "source": [
    "**9) Plot the evolution of the training and validation accuracy as a function of the number of epochs. Comment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "DVOoemUax8Id",
    "outputId": "6bfad72c-2e35-4b55-e1fa-8d2c0717a149"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IheuFuwN9dWK"
   },
   "source": [
    "**10) Evaluate the performance of the final neural network on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RPVKXsKmfL9",
    "outputId": "557e945b-2269-4de5-a437-b77f7a6bfc3a"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
