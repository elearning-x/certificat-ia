{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzoF42h47ec5"
   },
   "source": [
    "# Random Forests and Tree Boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uCLPSBQ7lJJ"
   },
   "source": [
    "## 1 - Regression \n",
    "\n",
    "In this part, we apply Random Forests and Tree Boosting on the real estate dataset that we have seen before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NsM6IZP7z4t"
   },
   "source": [
    "**1) Load the data, split the data into a train set (80%) and a test set (20%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_467tVI7bwm"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "house = fetch_california_housing()\n",
    "X, y = house.data, house.target\n",
    "feature_names = house.feature_names\n",
    "\n",
    "feature_mapping = {\n",
    "    \"MedInc\": \"Median income in block\",\n",
    "    \"HousAge\": \"Median house age in block\",\n",
    "    \"AveRooms\": \"Average number of rooms\",\n",
    "    \"AveBedrms\": \"Average number of bedrooms\",\n",
    "    \"Population\": \"Block population\",\n",
    "    \"AveOccup\": \"Average house occupancy\",\n",
    "    \"Latitude\": \"House block latitude\",\n",
    "    \"Longitude\": \"House block longitude\",\n",
    "}\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2b6JRz78H84"
   },
   "source": [
    "**2) Train a random forests with default parameters on these data and evaluate its performance on the training set and test set. Comment.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0y121cCX8Ko7",
    "outputId": "a62a9eea-111a-4849-f37b-5d70e029b918"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzkV32dbKjJq"
   },
   "source": [
    "**3) Based on the lecture, which parameter could have the biggest impact on the predictive performances of the forest? Plot the error of the forest as a function of this parameter.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "OkkqDhjM-s5c",
    "outputId": "5d037417-45a0-4f13-de3c-07b58b41c619"
   },
   "outputs": [],
   "source": [
    "# The parameter that can have the greatest impact on the prediction is the max-features \n",
    "# (the number of randomly selected directions for splitting in each node).\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS1PMAaUPRHs"
   },
   "source": [
    "**4) Train a forest with the best parameter found above. Comment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Bthu_we-wAy",
    "outputId": "99ea8f6c-f46d-4c8d-b3e5-0cd41268b60f"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUmEbY3zKT1H"
   },
   "source": [
    "**5) Now, optimize jointly the parameters 'max-features' and 'max-depth' of the random forest. You can use the function 'GridSearchCV'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "rNox9161XZve",
    "outputId": "e3fdef41-ff93-48fc-e23b-879242b0b15b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdTrK1TkKT34"
   },
   "source": [
    "**6) Train the best resulting model and compute its error.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcHE1B70YsRm",
    "outputId": "e820f2ff-4c9d-4eea-cf39-f5925b15aae9"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkLVgqLFKT6w"
   },
   "source": [
    "**7) Train a Gradient Boosting Decision Tree using 'GradientBoostingRegressor'. Tune the hyperparameters 'learning_rate' and 'max_depth' via cross-validation as above. Comment the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 413
    },
    "id": "d5Mr3eCXh8Kh",
    "outputId": "9b74d84e-caf6-4e01-8fab-6011f98bcdd1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YCAyUZaVoWJ1",
    "outputId": "a4121c54-689c-4b4a-9833-fc8d54e9899a"
   },
   "outputs": [],
   "source": [
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHLF9CROKUCi"
   },
   "source": [
    "## 2 - Classification on a Toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "_ymeScRXKY2r",
    "outputId": "70dc515e-d2ab-4d97-89be-a00b146d2333"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Create an imbalanced dataset\n",
    "X, y = make_classification(n_samples=5000,weights=[0.02, 0.98],\n",
    "                           random_state=0,n_clusters_per_class=1)\n",
    "\n",
    "# Generate a classification dataset composed of two circles\n",
    "#X, y = make_circles(n_samples=(200, 10), noise=0.1)\n",
    "\n",
    "# Plot the generated dataset\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='bwr')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Generated Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyCBtJ5YjoKo"
   },
   "source": [
    "**8) Split the data set into a train and a test set. Train a random forest with max_depth = 2 on the training set. Plot its performance with a confusion matrix on the test set. Comment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEkq-g9YjywZ",
    "outputId": "69da31e5-e80b-4496-c7b8-3097c4db75d3"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle = True)\n",
    "\n",
    "\n",
    "# TO DO \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# END TO DO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QBk_Zlmjy-H"
   },
   "source": [
    "In presence of an imbalanced data set, we need to pay attention to two different things: \n",
    "- when dividing the dataset into several parts (training/test), we want to keep the same proportion of observations in the resulting datasets. To do so, we use stratification. \n",
    "- we need to rebalance the training set so that it contains roughly the same proportions for the two classes. This can be done via the parameter 'class_weight'. It thus helps the training process by weighting up observations from the minority class. \n",
    "No matter what you do on the training set, you are not allowed to change the test set. It must reflect the true distribution of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p16OrnTUkjMU"
   },
   "source": [
    "**9) Implement these modifications, train a forest and compare its performances.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_z1mqxpWdL7S",
    "outputId": "8d48c83d-6b33-4549-eaf8-4c5bffafe854"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TO DO \n",
    "\n",
    "# END TO DO "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
